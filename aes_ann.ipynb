{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ja_pgwrhmBD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "NB = 4\n",
        "left = 0\n",
        "right = 1\n",
        "\n",
        "S = [\n",
        "    0x63, 0x7c, 0x77, 0x7b, 0xf2, 0x6b, 0x6f, 0xc5, 0x30, 0x01, 0x67, 0x2b, 0xfe, 0xd7, 0xab, 0x76,\n",
        "    0xca, 0x82, 0xc9, 0x7d, 0xfa, 0x59, 0x47, 0xf0, 0xad, 0xd4, 0xa2, 0xaf, 0x9c, 0xa4, 0x72, 0xc0,\n",
        "    0xb7, 0xfd, 0x93, 0x26, 0x36, 0x3f, 0xf7, 0xcc, 0x34, 0xa5, 0xe5, 0xf1, 0x71, 0xd8, 0x31, 0x15,\n",
        "    0x04, 0xc7, 0x23, 0xc3, 0x18, 0x96, 0x05, 0x9a, 0x07, 0x12, 0x80, 0xe2, 0xeb, 0x27, 0xb2, 0x75,\n",
        "    0x09, 0x83, 0x2c, 0x1a, 0x1b, 0x6e, 0x5a, 0xa0, 0x52, 0x3b, 0xd6, 0xb3, 0x29, 0xe3, 0x2f, 0x84,\n",
        "    0x53, 0xd1, 0x00, 0xed, 0x20, 0xfc, 0xb1, 0x5b, 0x6a, 0xcb, 0xbe, 0x39, 0x4a, 0x4c, 0x58, 0xcf,\n",
        "    0xd0, 0xef, 0xaa, 0xfb, 0x43, 0x4d, 0x33, 0x85, 0x45, 0xf9, 0x02, 0x7f, 0x50, 0x3c, 0x9f, 0xa8,\n",
        "    0x51, 0xa3, 0x40, 0x8f, 0x92, 0x9d, 0x38, 0xf5, 0xbc, 0xb6, 0xda, 0x21, 0x10, 0xff, 0xf3, 0xd2,\n",
        "    0xcd, 0x0c, 0x13, 0xec, 0x5f, 0x97, 0x44, 0x17, 0xc4, 0xa7, 0x7e, 0x3d, 0x64, 0x5d, 0x19, 0x73,\n",
        "    0x60, 0x81, 0x4f, 0xdc, 0x22, 0x2a, 0x90, 0x88, 0x46, 0xee, 0xb8, 0x14, 0xde, 0x5e, 0x0b, 0xdb,\n",
        "    0xe0, 0x32, 0x3a, 0x0a, 0x49, 0x06, 0x24, 0x5c, 0xc2, 0xd3, 0xac, 0x62, 0x91, 0x95, 0xe4, 0x79,\n",
        "    0xe7, 0xc8, 0x37, 0x6d, 0x8d, 0xd5, 0x4e, 0xa9, 0x6c, 0x56, 0xf4, 0xea, 0x65, 0x7a, 0xae, 0x08,\n",
        "    0xba, 0x78, 0x25, 0x2e, 0x1c, 0xa6, 0xb4, 0xc6, 0xe8, 0xdd, 0x74, 0x1f, 0x4b, 0xbd, 0x8b, 0x8a,\n",
        "    0x70, 0x3e, 0xb5, 0x66, 0x48, 0x03, 0xf6, 0x0e, 0x61, 0x35, 0x57, 0xb9, 0x86, 0xc1, 0x1d, 0x9e,\n",
        "    0xe1, 0xf8, 0x98, 0x11, 0x69, 0xd9, 0x8e, 0x94, 0x9b, 0x1e, 0x87, 0xe9, 0xce, 0x55, 0x28, 0xdf,\n",
        "    0x8c, 0xa1, 0x89, 0x0d, 0xbf, 0xe6, 0x42, 0x68, 0x41, 0x99, 0x2d, 0x0f, 0xb0, 0x54, 0xbb, 0x16\n",
        "]\n",
        "\n",
        "IS = [\n",
        "    0x52, 0x09, 0x6a, 0xd5, 0x30, 0x36, 0xa5, 0x38, 0xbf, 0x40, 0xa3, 0x9e, 0x81, 0xf3, 0xd7, 0xfb,\n",
        "    0x7c, 0xe3, 0x39, 0x82, 0x9b, 0x2f, 0xff, 0x87, 0x34, 0x8e, 0x43, 0x44, 0xc4, 0xde, 0xe9, 0xcb,\n",
        "    0x54, 0x7b, 0x94, 0x32, 0xa6, 0xc2, 0x23, 0x3d, 0xee, 0x4c, 0x95, 0x0b, 0x42, 0xfa, 0xc3, 0x4e,\n",
        "    0x08, 0x2e, 0xa1, 0x66, 0x28, 0xd9, 0x24, 0xb2, 0x76, 0x5b, 0xa2, 0x49, 0x6d, 0x8b, 0xd1, 0x25,\n",
        "    0x72, 0xf8, 0xf6, 0x64, 0x86, 0x68, 0x98, 0x16, 0xd4, 0xa4, 0x5c, 0xcc, 0x5d, 0x65, 0xb6, 0x92,\n",
        "    0x6c, 0x70, 0x48, 0x50, 0xfd, 0xed, 0xb9, 0xda, 0x5e, 0x15, 0x46, 0x57, 0xa7, 0x8d, 0x9d, 0x84,\n",
        "    0x90, 0xd8, 0xab, 0x00, 0x8c, 0xbc, 0xd3, 0x0a, 0xf7, 0xe4, 0x58, 0x05, 0xb8, 0xb3, 0x45, 0x06,\n",
        "    0xd0, 0x2c, 0x1e, 0x8f, 0xca, 0x3f, 0x0f, 0x02, 0xc1, 0xaf, 0xbd, 0x03, 0x01, 0x13, 0x8a, 0x6b,\n",
        "    0x3a, 0x91, 0x11, 0x41, 0x4f, 0x67, 0xdc, 0xea, 0x97, 0xf2, 0xcf, 0xce, 0xf0, 0xb4, 0xe6, 0x73,\n",
        "    0x96, 0xac, 0x74, 0x22, 0xe7, 0xad, 0x35, 0x85, 0xe2, 0xf9, 0x37, 0xe8, 0x1c, 0x75, 0xdf, 0x6e,\n",
        "    0x47, 0xf1, 0x1a, 0x71, 0x1d, 0x29, 0xc5, 0x89, 0x6f, 0xb7, 0x62, 0x0e, 0xaa, 0x18, 0xbe, 0x1b,\n",
        "    0xfc, 0x56, 0x3e, 0x4b, 0xc6, 0xd2, 0x79, 0x20, 0x9a, 0xdb, 0xc0, 0xfe, 0x78, 0xcd, 0x5a, 0xf4,\n",
        "    0x1f, 0xdd, 0xa8, 0x33, 0x88, 0x07, 0xc7, 0x31, 0xb1, 0x12, 0x10, 0x59, 0x27, 0x80, 0xec, 0x5f,\n",
        "    0x60, 0x51, 0x7f, 0xa9, 0x19, 0xb5, 0x4a, 0x0d, 0x2d, 0xe5, 0x7a, 0x9f, 0x93, 0xc9, 0x9c, 0xef,\n",
        "    0xa0, 0xe0, 0x3b, 0x4d, 0xae, 0x2a, 0xf5, 0xb0, 0xc8, 0xeb, 0xbb, 0x3c, 0x83, 0x53, 0x99, 0x61,\n",
        "    0x17, 0x2b, 0x04, 0x7e, 0xba, 0x77, 0xd6, 0x26, 0xe1, 0x69, 0x14, 0x63, 0x55, 0x21, 0x0c, 0x7d\n",
        "]\n",
        "\n",
        "def show_vector_as_matrix(v):\n",
        "    for i in range(4):\n",
        "        print(\"\\t\", end = \"\")\n",
        "        for j in range(4):\n",
        "            print(f\"{v[i + j * 4]:02x}\", end = \"\")\n",
        "        print()\n",
        "\n",
        "def show_vector_as_word(v):\n",
        "    for i in range(4):\n",
        "        print(\"\\t\", end = \"\")\n",
        "        for j in range(4):\n",
        "            print(f\"{v[i * 4 + j]:02x}\", end = \"\")\n",
        "        print()\n",
        "\n",
        "def print_vector_hex(v):\n",
        "    for e in v:\n",
        "        print(f\"{e:02x}\", end = \" \")\n",
        "\n",
        "def XOR(v1, v2):\n",
        "    return np.array(v1, dtype=np.uint8) ^ np.array(v2, dtype=np.uint8)\n",
        "\n",
        "def nhan2(b: int) -> int:\n",
        "    rs = b << 1\n",
        "    if rs & 0x80 != 0:\n",
        "        rs ^= 0x1b\n",
        "    return rs & 0xff\n",
        "\n",
        "def nhan3(w: int) -> int:\n",
        "    return nhan2(w) ^ w\n",
        "\n",
        "def nhan9(w: int) -> int:\n",
        "    return nhan2(nhan2(nhan2(w))) ^ w\n",
        "\n",
        "def nhanB(w: int) -> int:\n",
        "    return nhan2(nhan2(nhan2(w))) ^ nhan2(w) ^ w\n",
        "\n",
        "def nhanD(w: int) -> int:\n",
        "    return nhan2(nhan2(nhan2(w))) ^ nhan2(nhan2(w)) ^ w\n",
        "\n",
        "def nhanE(w: int) -> int:\n",
        "    return nhan2(nhan2(nhan2(w))) ^ nhan2(nhan2(w)) ^ nhan2(w)\n",
        "\n",
        "def nhanCot_encrypt(v):\n",
        "    rs = np.full(4, 0)\n",
        "    rs[0] = nhan2(v[0]) ^ nhan3(v[1]) ^ v[2] ^ v[3]\n",
        "    rs[1] = v[0] ^ nhan2(v[1]) ^ nhan3(v[2]) ^ v[3]\n",
        "    rs[2] = v[0] ^ v[1] ^ nhan2(v[2]) ^ nhan3(v[3])\n",
        "    rs[3] = nhan3(v[0]) ^ v[1] ^ v[2] ^ nhan2(v[3])\n",
        "    return rs\n",
        "\n",
        "def nhanCot_decrypt(v):\n",
        "    rs = np.full(4, 0)\n",
        "    rs[0] = nhanE(v[0]) ^ nhanB(v[1]) ^ nhanD(v[2]) ^ nhan9(v[3])\n",
        "    rs[1] = nhan9(v[0]) ^ nhanE(v[1]) ^ nhanB(v[2]) ^ nhanD(v[3])\n",
        "    rs[2] = nhanD(v[0]) ^ nhan9(v[1]) ^ nhanE(v[2]) ^ nhanB(v[3])\n",
        "    rs[3] = nhanB(v[0]) ^ nhanD(v[1]) ^ nhan9(v[2]) ^ nhanE(v[3])\n",
        "    return rs\n",
        "\n",
        "def shift_left(v):\n",
        "    return np.array([v[1], v[2], v[3], v[0]])\n",
        "\n",
        "def shift_right(v):\n",
        "    return np.array([v[3], v[0], v[1], v[2]])\n",
        "\n",
        "def shift(v, direction, times = 1):\n",
        "    rs = v\n",
        "    for _ in range(times):\n",
        "        if direction == left:\n",
        "            rs = shift_left(rs)\n",
        "        elif direction == right:\n",
        "            rs = shift_right(rs)\n",
        "    return rs\n",
        "\n",
        "def rot_word(v):\n",
        "    return np.array([v[1], v[2], v[3], v[0]])\n",
        "\n",
        "def sub_word(v, box):\n",
        "    rs = np.full(4, 0)\n",
        "    for i in range(4):\n",
        "        rs[i] = box[v[i]]\n",
        "    return rs\n",
        "\n",
        "Rcon = [\n",
        "    0x00,\n",
        "    0x01, 0x02, 0x04, 0x08, 0x10,\n",
        "    0x20, 0x40, 0x80, 0x1b, 0x36\n",
        "]\n",
        "\n",
        "def XOR_Rcon(v, i):\n",
        "    return np.array([v[0] ^ Rcon[int(i)], v[1], v[2], v[3]])\n",
        "\n",
        "def key_expansion(key, nk, nr):\n",
        "    expansion = np.full((NB * (nr + 1)) * 4, 0)\n",
        "    for i in range(nk * 4):\n",
        "        expansion[i] = key[i]\n",
        "\n",
        "    for i in range(nk, NB * (nr + 1)):\n",
        "        temp = expansion[(i - 1) * 4:(i - 1) * 4 + 4]\n",
        "        if i % nk == 0:\n",
        "            temp = sub_word(rot_word(temp), S)\n",
        "            temp = XOR_Rcon(temp, i / nk)\n",
        "        elif nk == 8 and i % nk == 4:\n",
        "            temp = sub_word(temp, S)\n",
        "        expansion[i * 4:(i * 4) + 4] = XOR(expansion[(i - nk) * 4:((i - nk) * 4) + 4], temp)\n",
        "\n",
        "    return expansion\n",
        "\n",
        "def sub_bytes(state):\n",
        "    rs = np.full(16, 0)\n",
        "    for i in range(4):\n",
        "        rs[i * 4:i * 4 + 4] = sub_word(state[i * 4:i * 4 + 4], S)\n",
        "    return rs\n",
        "\n",
        "def shift_rows(state):\n",
        "    rs = np.full(16, 0)\n",
        "    for i in range(4):\n",
        "        rs[i::4] = shift(state[i::4], left, i)\n",
        "    return rs\n",
        "\n",
        "def mix_columns(state):\n",
        "    rs = np.full(16, 0)\n",
        "    for i in range(4):\n",
        "        rs[i * 4:i * 4 + 4] = nhanCot_encrypt(state[i * 4:i * 4 + 4])\n",
        "    return rs\n",
        "\n",
        "def add_round_key(state, roundKey):\n",
        "    rs = np.full(16, 0)\n",
        "    for i in range(4):\n",
        "        ind = i * 4\n",
        "        rs[ind:ind + 4] = XOR(state[ind:ind + 4], roundKey[ind:ind + 4])\n",
        "    return rs\n",
        "\n",
        "def encrypt(state, roundKeys, nk, nr):\n",
        "    rs = np.full(16, 0)\n",
        "    rs = add_round_key(state, roundKeys[0:16])\n",
        "\n",
        "    for i in range(1, nr):\n",
        "        rs = sub_bytes(rs)\n",
        "        rs = shift_rows(rs)\n",
        "        rs = mix_columns(rs)\n",
        "        rs = add_round_key(rs, roundKeys[i * 16:(i + 1) * 16])\n",
        "\n",
        "    rs = sub_bytes(rs)\n",
        "    rs = shift_rows(rs)\n",
        "    rs = add_round_key(rs, roundKeys[nr * 16:(nr + 1) * 16])\n",
        "\n",
        "    return rs\n",
        "\n",
        "def inv_shift_rows(state):\n",
        "    rs = np.full(16, 0)\n",
        "    for i in range(4):\n",
        "        rs[i::4] = shift(state[i::4], right, i)\n",
        "    return rs\n",
        "\n",
        "def inv_sub_bytes(state):\n",
        "    rs = np.full(16, 0)\n",
        "    for i in range(4):\n",
        "        rs[i * 4:i * 4 + 4] = sub_word(state[i * 4:i * 4 + 4], IS)\n",
        "    return rs\n",
        "\n",
        "def inv_mix_columns(state):\n",
        "    rs = np.full(16, 0)\n",
        "    for i in range(4):\n",
        "        rs[i * 4:i * 4 + 4] = nhanCot_decrypt(state[i * 4:i * 4 + 4])\n",
        "    return rs\n",
        "\n",
        "def decrypt(state, roundKeys, nk, nr):\n",
        "    rs = np.full(16, 0)\n",
        "    rs = add_round_key(state, roundKeys[nr * 16:(nr + 1) * 16])\n",
        "\n",
        "    for i in range(nr - 1, 0, -1):\n",
        "        rs = inv_shift_rows(rs)\n",
        "        rs = inv_sub_bytes(rs)\n",
        "        rs = add_round_key(rs, roundKeys[i * 16:(i + 1) * 16])\n",
        "        rs = inv_mix_columns(rs)\n",
        "\n",
        "    rs = inv_shift_rows(rs)\n",
        "    rs = inv_sub_bytes(rs)\n",
        "    rs = add_round_key(rs, roundKeys[0:16])\n",
        "\n",
        "    return rs\n",
        "\n",
        "def str_to_vector_hex(s: str):\n",
        "    return np.array([ord(c) for c in s])\n",
        "\n",
        "def vector_hex_to_str(v):\n",
        "    return \"\".join([chr(e) for e in v])\n",
        "\n",
        "def hex_str_to_vector_hex(s: str):\n",
        "    return np.array([int(s[i:i + 2], 16) for i in range(0, len(s), 2)])\n",
        "\n",
        "def vector_hex_to_hex_str(v):\n",
        "    return \"\".join([f\"{e:02x}\" for e in v])\n",
        "\n",
        "def padding(v):\n",
        "    pads = 16 - len(v) % 16\n",
        "    if pads < 16:\n",
        "        return np.append(v, np.full(pads, pads))\n",
        "    return v\n",
        "\n",
        "def remove_padding(v):\n",
        "    pads = v[len(v) - 1]\n",
        "    count = 0\n",
        "    for e in v[::-1]:\n",
        "        count += 1\n",
        "        if e != pads:\n",
        "            return v\n",
        "        if count == pads:\n",
        "            break\n",
        "    return v[:len(v) - pads]\n",
        "\n",
        "def random_vector(block_size = 16):\n",
        "    return np.random.randint(0, 256, size = block_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVVLmFgFlF1a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "def prepare_sub_bytes_data(num_samples = 100000):\n",
        "  inputs = np.random.randint(0, 256, (num_samples, 16), dtype = np.uint8)\n",
        "  outputs = np.array([sub_bytes(block) for block in inputs])\n",
        "\n",
        "  with open(\"sub_bytes_inputs.txt\", \"w\") as f:\n",
        "    for i in range(num_samples):\n",
        "        input_str = \" \".join([f\"{x:02x}\" for x in inputs[i]])\n",
        "        f.write(f\"{input_str}\\n\")\n",
        "\n",
        "  with open(\"sub_bytes_outputs.txt\", \"w\") as f:\n",
        "    for i in range(num_samples):\n",
        "        output_str = \" \".join([f\"{x:02x}\" for x in outputs[i]])\n",
        "        f.write(f\"{output_str}\\n\")\n",
        "\n",
        "  return inputs, outputs\n",
        "\n",
        "def prepare_mix_columns_data(num_samples = 100000):\n",
        "  inputs = np.random.randint(0, 256, (num_samples, 16), dtype = np.uint8)\n",
        "  outputs = np.array([mix_columns(block) for block in inputs])\n",
        "\n",
        "  with open(\"mix_columns_inputs.txt\", \"w\") as f:\n",
        "    for i in range(num_samples):\n",
        "        input_str = \" \".join([f\"{x:02x}\" for x in inputs[i]])\n",
        "        f.write(f\"{input_str}\\n\")\n",
        "\n",
        "  with open(\"mix_columns_outputs.txt\", \"w\") as f:\n",
        "    for i in range(num_samples):\n",
        "        output_str = \" \".join([f\"{x:02x}\" for x in outputs[i]])\n",
        "        f.write(f\"{output_str}\\n\")\n",
        "\n",
        "  return inputs, outputs\n",
        "\n",
        "# key length = 128\n",
        "def prepare_key_expansion_data(num_samples = 100000):\n",
        "  keys = np.random.randint(0, 256, (num_samples, 16), dtype = np.uint8)\n",
        "  round_keys = np.array([key_expansion(key, 4, 10) for key in keys])\n",
        "\n",
        "  with open(\"key_expansion_inputs.txt\", \"w\") as f:\n",
        "    for i in range(num_samples):\n",
        "        key_str = \" \".join([f\"{x:02x}\" for x in keys[i]])\n",
        "        f.write(f\"{key_str}\\n\")\n",
        "\n",
        "  with open(\"key_expansion_outputs.txt\", \"w\") as f:\n",
        "      for i in range(num_samples):\n",
        "          round_key_str = \" \".join([f\"{x:02x}\" for x in round_keys[i]])\n",
        "          f.write(f\"{round_key_str}\\n\")\n",
        "\n",
        "  return keys, round_keys\n",
        "\n",
        "def prepare_encryption_data(round_keys, num_saples = 100000):\n",
        "  inputs = np.random.randint(0, 256, (num_saples, 16), dtype = np.uint8)\n",
        "  outputs = np.array([encrypt(block, round_keys, 4, 10) for block in inputs])\n",
        "  return inputs, outputs\n",
        "\n",
        "def save_data(X, y, filename):\n",
        "  with open(filename, 'wb') as f:\n",
        "    pickle.dump((X, y), f)\n",
        "\n",
        "def load_data(filename):\n",
        "  with open(filename, 'rb') as f:\n",
        "    X, y = pickle.load(f)\n",
        "  return X, y\n",
        "\n",
        "def encrypt_with_models(state, key, sub_bytes_model, mix_columns_model, key_expansion_model, nr):\n",
        "  state = padding(state)\n",
        "  round_keys = key_expansion_model.predict(np.array([key])).reshape(-1)\n",
        "\n",
        "  state = add_round_key(state, round_keys[0:16])\n",
        "\n",
        "  for i in range(1, nr):\n",
        "    state = sub_bytes_model.predict(np.array([state])).reshape(-1)\n",
        "    state = shift_rows(state)\n",
        "    state = mix_columns_model.predict(np.array([state])).reshape(-1)\n",
        "    state = add_round_key(state, round_keys[i * 16:(i + 1) * 16])\n",
        "\n",
        "  state = sub_bytes_model.predict(np.array([state])).reshape(-1)\n",
        "  state = shift_rows(state)\n",
        "  state = add_round_key(state, round_keys[nr * 16:(nr + 1) * 16])\n",
        "\n",
        "  return state\n",
        "\n",
        "def measure_encryption_time(state, key, sub_bytes_model, mix_columns_model, key_expansion_model, nk, nr):\n",
        "  start_time = time.time()\n",
        "  roundKeys = key_expansion(key, nk, nr)\n",
        "  cipherytext_without_models = encrypt(state, roundKeys, nk, nr)\n",
        "  time_without_models = time.time() - start_time\n",
        "  print(f\"AES without models:{time_without_models:.6f} seconds\")\n",
        "\n",
        "  start_time = time.time()\n",
        "  cihpertext_with_models = encrypt_with_models(state, key, sub_bytes_model, mix_columns_model, key_expansion_model, nr)\n",
        "  time_with_models = time.time() - start_time\n",
        "  print(f\"AES with models:{time_with_models:.6f} seconds\")\n",
        "\n",
        "  # return time_without_models, time_with_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nU-CuIn2vq9c"
      },
      "outputs": [],
      "source": [
        "def train_sub_bytes_model(_epochs = 10, _batch_size = 32):\n",
        "  X, y = load_data(\"sub_bytes_data.pkl\")\n",
        "  learning_rate = 0.01  # Giá trị learning rate cao hơn\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(128, activation='relu', input_shape=(X.shape[1],),\n",
        "                            kernel_regularizer=regularizers.l2(0.01)), # thêm hình phạt vào hàm mất mát\n",
        "      tf.keras.layers.Dropout(0.3), # ngẫu nhiên bỏ qua 1 số neuron\n",
        "      tf.keras.layers.Dense(256, activation='relu',\n",
        "                            kernel_regularizer=regularizers.l2(0.01)),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "      tf.keras.layers.Dense(y.shape[1])\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "  model.fit(X, y, epochs=_epochs, batch_size=_batch_size, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
        "  model.save(\"sub_bytes_model.h5\")\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PY6DiUhq0jnr"
      },
      "outputs": [],
      "source": [
        "sub_bytes_inputs, sub_bytes_outputs = prepare_sub_bytes_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bSXmGRKwBLb"
      },
      "outputs": [],
      "source": [
        "def train_mix_columns_model(_epochs = 10, _batch_size = 32):\n",
        "  X, y = load_data(\"mix_columns_data.pkl\")\n",
        "  learning_rate = 0.01  # Giá trị learning rate cao hơn\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(128, activation='relu', input_shape=(X.shape[1],),\n",
        "                            kernel_regularizer=regularizers.l2(0.01)),\n",
        "      tf.keras.layers.Dropout(0.3),\n",
        "      tf.keras.layers.Dense(256, activation='relu',\n",
        "                            kernel_regularizer=regularizers.l2(0.01)),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "      tf.keras.layers.Dense(y.shape[1])\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "  model.fit(X, y, epochs=_epochs, batch_size=_batch_size, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
        "  model.save(\"mix_columns_model.h5\")\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FO_LzC__0mfh"
      },
      "outputs": [],
      "source": [
        "mix_columns_inputs, mix_columns_outputs = prepare_mix_columns_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdIel4qBqi85"
      },
      "outputs": [],
      "source": [
        "def train_key_expansion_model(X, y, _epochs = 10, _batch_size = 32):\n",
        "  # X, y = load_data(\"key_expansion_data.pkl\")\n",
        "  learning_rate = 0.001\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(256, activation='relu', input_shape=(X.shape[1],),\n",
        "                              kernel_regularizer=regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(512, activation='relu',\n",
        "                              kernel_regularizer=regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(256, activation='relu',\n",
        "                              kernel_regularizer=regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(y.shape[1])\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "  model.fit(X_train, y_train, epochs=_epochs, batch_size=_batch_size,\n",
        "              validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr])\n",
        "  model.save(\"key_expansion_model.h5\")\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIDqJaxJyG8i"
      },
      "outputs": [],
      "source": [
        "key_expansion_inputs, key_expansion_outputs = prepare_key_expansion_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "InejBziEqZei",
        "outputId": "bf559cc7-51f7-4547-ec77-dc84f5b025e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 6449.0752 - val_loss: 5494.9033 - learning_rate: 0.0100\n",
            "Epoch 2/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 5567.7764 - val_loss: 5483.4639 - learning_rate: 0.0100\n",
            "Epoch 3/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5565.2437 - val_loss: 5479.9038 - learning_rate: 0.0100\n",
            "Epoch 4/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 5549.0713 - val_loss: 5485.8057 - learning_rate: 0.0100\n",
            "Epoch 5/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 5594.2534 - val_loss: 5475.5254 - learning_rate: 0.0100\n",
            "Epoch 6/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 5811.9331 - val_loss: 7236.6704 - learning_rate: 0.0100\n",
            "Epoch 7/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 6702.6460 - val_loss: 6292.9570 - learning_rate: 0.0100\n",
            "Epoch 8/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 6052.3066 - val_loss: 5483.2002 - learning_rate: 0.0100\n",
            "Epoch 9/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 5544.3013 - val_loss: 5472.8608 - learning_rate: 0.0100\n",
            "Epoch 10/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 5518.3232 - val_loss: 5482.3257 - learning_rate: 0.0100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# train models\n",
        "sub_bytes_model = train_sub_bytes_model(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bElGG3RkUgfZ",
        "outputId": "6c65609d-17ee-4880-c05b-5e29a179b053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 6442.1641 - val_loss: 5479.0322 - learning_rate: 0.0100\n",
            "Epoch 2/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 5598.9277 - val_loss: 5482.7490 - learning_rate: 0.0100\n",
            "Epoch 3/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 5576.9888 - val_loss: 5489.4189 - learning_rate: 0.0100\n",
            "Epoch 4/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 5573.1948 - val_loss: 5474.3613 - learning_rate: 0.0100\n",
            "Epoch 5/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 5562.8472 - val_loss: 5472.5586 - learning_rate: 0.0100\n",
            "Epoch 6/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 5848.7534 - val_loss: 6748.6401 - learning_rate: 0.0100\n",
            "Epoch 7/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 6130.1875 - val_loss: 5849.2715 - learning_rate: 0.0100\n",
            "Epoch 8/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 5821.0410 - val_loss: 5477.6875 - learning_rate: 0.0100\n",
            "Epoch 9/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 5574.4229 - val_loss: 5474.7046 - learning_rate: 0.0100\n",
            "Epoch 10/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 5535.1772 - val_loss: 5476.8262 - learning_rate: 0.0100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "mix_columns_model = train_mix_columns_model(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cIT6Iu4DUlNg",
        "outputId": "0dfc79b2-7187-4a30-923b-fd3eb7421f45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.0236 - loss: 6282.5962 - val_accuracy: 0.0628 - val_loss: 6318.1792 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.0394 - loss: 5591.0552 - val_accuracy: 0.0674 - val_loss: 6017.0762 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0426 - loss: 5506.8179 - val_accuracy: 0.0639 - val_loss: 5599.4214 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.0417 - loss: 5402.2021 - val_accuracy: 0.0675 - val_loss: 5256.9370 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.0423 - loss: 5311.2646 - val_accuracy: 0.0653 - val_loss: 5130.9058 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0441 - loss: 5269.6914 - val_accuracy: 0.0697 - val_loss: 5124.3340 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.0432 - loss: 5234.2173 - val_accuracy: 0.0701 - val_loss: 5086.8950 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.0438 - loss: 5226.1616 - val_accuracy: 0.0681 - val_loss: 5096.2949 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.0434 - loss: 5224.3359 - val_accuracy: 0.0698 - val_loss: 5092.8979 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0432 - loss: 5224.4541 - val_accuracy: 0.0689 - val_loss: 5083.3330 - learning_rate: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "key_expansion_model = train_key_expansion_model(key_expansion_inputs, key_expansion_outputs, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcldp7B4QYEk"
      },
      "outputs": [],
      "source": [
        "state = random_vector()\n",
        "key = random_vector()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl7tKKHlbf2F",
        "outputId": "e4808906-973e-46bd-d80f-002210177414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
            "[170 111 162  77 165  99 174  83  77 143 166  53 139 170  71 173 129 125\n",
            " 132 126 127 128 129 125 132 131 128 129 123 128 129 126 129 126 125 125\n",
            " 131 122 127 126 129 129 124 125 125 128 128 128 128 125 127 129 128 129\n",
            " 131 128 129 129 128 127 126 127 128 128 128 128 128 133 125 128 128 131\n",
            " 128 126 124 130 124 126 123 127 126 128 130 129 124 128 128 131 122 126\n",
            " 126 126 122 125 124 128 130 127 130 131 127 127 125 126 127 128 129 128\n",
            " 127 128 127 131 126 127 126 129 128 130 126 123 130 125 126 129 125 126\n",
            " 125 125 124 129 128 126 126 129 128 130 123 125 130 130 123 132 131 130\n",
            " 126 127 127 127 125 121 126 130 127 128 127 127 125 125 125 127 125 127\n",
            " 130 126 128 131 128 129 132 127 128 130 130 123 128 127]\n"
          ]
        }
      ],
      "source": [
        "print(key_expansion_model.predict(np.array([key])).reshape(-1).astype(np.uint8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bymxkzc1c2hk",
        "outputId": "ef711bab-6ba1-4217-acfc-b0684d93e236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[201 117 182  73 180 114 194  70  44 159 228  37 158 219  47 202 113  96\n",
            " 194  66 197  18   0   4 233 141 228  33 119  86 203 235 194 127  43 183\n",
            "   7 109  43 179 238 224 207 146 153 182   4 121 136 141 157  89 143 224\n",
            " 182 234  97   0 121 120 248 182 125   1 206 114 225  24  65 146  87 242\n",
            "  32 146  46 138 216  36  83 139 232 159 220 121 169  13 139 139 137 159\n",
            " 165   1  81 187 246 138  34 221 162 168 139 208  41  35   2  79 140  34\n",
            "  83 244 122 168 221   7  96  69  86 215  73 102  84 152 197  68   7 108\n",
            " 191 236  13  15 174 128  91 216 231 230  15  64  34 162   8  44 157  78\n",
            " 103  81 129 176  60 137 102  86  51 201  68 244  59 229 217 186 136 100\n",
            " 117  82 180 237  19   4 135  36  87 240 188 193 142  74]\n"
          ]
        }
      ],
      "source": [
        "print(key_expansion(key, 4, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AF4IVGWse5Pc",
        "outputId": "31dd31eb-83b3-4b4b-e38d-4ac454074b2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AES without models:0.001678 seconds\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "AES with models:2.512937 seconds\n"
          ]
        }
      ],
      "source": [
        "measure_encryption_time(state, key, sub_bytes_model, mix_columns_model, key_expansion_model, 4, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl7LrQB7vhfb"
      },
      "source": [
        "- mô hình đang bị mắc kẹt cục bộ trong local minimum (cực tiểu cục bộ) -> thay đổi optimizer\n",
        "- mô hình quá đơn giản -> thêm layer hoặc nơ ron\n",
        "- có khả năng hàm mất mát không phù hợp\n",
        "\n",
        "=> chưa đủ khả năng và kiến thức để xử lý"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "LEX72lGj016U"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
